{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "\n",
    "# tensorflow imports\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model,Model\n",
    "from tensorflow.keras.layers import (Dense, LSTM, Bidirectional, Input, Concatenate, \n",
    "                                     Permute, Dot, Multiply, RepeatVector,Lambda,Activation)\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading data\n",
    "nmt_data = pd.read_csv(r'NMT_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{' ': 0, '/': 1, '0': 2, '1': 3, '2': 4, '3': 5, '4': 6, '5': 7, '6': 8, '7': 9, '8': 10, '9': 11, 'a': 12, 'b': 13, 'c': 14, 'd': 15, 'e': 16, 'f': 17, 'g': 18, 'h': 19, 'i': 20, 'j': 21, 'l': 22, 'm': 23, 'n': 24, 'o': 25, 'p': 26, 'r': 27, 's': 28, 't': 29, 'u': 30, 'v': 31, 'w': 32, 'y': 33, '<unk>': 34, '<pad>': 35}\n"
     ]
    }
   ],
   "source": [
    "# creating a vocabulary for human_readable_dates\n",
    "\n",
    "all_char = [char for word in list(nmt_data['human_readable_date']) for char in word]\n",
    "all_distinct_char = list(set(all_char))\n",
    "all_distinct_char.sort()\n",
    "human_readable_dates_vocab = {el:idx for idx,el in enumerate(all_distinct_char)}\n",
    "\n",
    "# adding <unk> and <pad> tokens at the end\n",
    "human_readable_dates_vocab['<unk>'] = len(all_distinct_char)\n",
    "human_readable_dates_vocab['<pad>'] = len(all_distinct_char) + 1\n",
    "\n",
    "print(human_readable_dates_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "char_as_key_dict :  {'-': 0, '0': 1, '1': 2, '2': 3, '3': 4, '4': 5, '5': 6, '6': 7, '7': 8, '8': 9, '9': 10}\n",
      "index_as_key_dixt :  {0: '-', 1: '0', 2: '1', 3: '2', 4: '3', 5: '4', 6: '5', 7: '6', 8: '7', 9: '8', 10: '9'}\n"
     ]
    }
   ],
   "source": [
    "# creating a vocabulary for machine_readable_dates\n",
    "\n",
    "all_char_m = [char for word in list(nmt_data['machine_readable_date']) for char in word]\n",
    "all_distinct_char_m = list(set(all_char_m))\n",
    "all_distinct_char_m.sort()\n",
    "machine_readable_dates_vocab = {el:idx for idx,el in enumerate(all_distinct_char_m)}\n",
    "inv_machine_readable_dates_vocab = {idx:el for idx,el in enumerate(all_distinct_char_m)}\n",
    "\n",
    "print(\"char_as_key_dict : \",machine_readable_dates_vocab)\n",
    "print(\"index_as_key_dixt : \",inv_machine_readable_dates_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eda to select max length for each date\n",
    "nmt_data['char_count'] = nmt_data['human_readable_date'].map(lambda x : len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert words to numbers\n",
    "def string_to_int(string, length, vocab):\n",
    "    string = string.lower()\n",
    "    string = string.replace(',','')\n",
    "    \n",
    "    if len(string) > length:\n",
    "        string = string[:length]\n",
    "        \n",
    "    rep = list(map(lambda x: vocab.get(x, '<unk>'), string))\n",
    "    \n",
    "    if len(string) < length:\n",
    "        rep += [vocab['<pad>']] * (length - len(string))\n",
    "    \n",
    "    return rep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(dataset, human_vocab, machine_vocab, Tx, Ty):\n",
    "    X, Y = zip(*dataset)\n",
    "    \n",
    "    X = np.array([string_to_int(i, Tx, human_vocab) for i in X])\n",
    "    Y = [string_to_int(t, Ty, machine_vocab) for t in Y]\n",
    "    \n",
    "    Xoh = np.array(list(map(lambda x: to_categorical(x, num_classes=len(human_vocab)), X)))\n",
    "    Yoh = np.array(list(map(lambda x: to_categorical(x, num_classes=len(machine_vocab)), Y)))\n",
    "\n",
    "    return X, np.array(Y), Xoh, Yoh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tx = length of each human_readable_date\n",
    "# Ty = length of each machine_readbale_date\n",
    "Tx = 30\n",
    "Ty = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorizer(list_of_values,max_length,value_dict):\n",
    "    \n",
    "    vector = []\n",
    "    for el in list_of_values:\n",
    "        if len(el) > max_length:\n",
    "            el   = el[:max_length]\n",
    "            vect = list(map(lambda x : value_dict.get(x,'<unk>')),el)\n",
    "        elif len(el) == max_length:\n",
    "            vect = list(map(lambda x : value_dict.get(x,'<unk>'),el))\n",
    "        else:\n",
    "            vect = list(map(lambda x : value_dict.get(x,'<unk>'),el)) + [value_dict['<pad>']] * (max_length - len(el))\n",
    "                        \n",
    "        vector.append(vect)\n",
    "        \n",
    "    return np.array(vector)\n",
    "               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = vectorizer(list(nmt_data['human_readable_date']),30,human_readable_dates_vocab)\n",
    "Y = vectorizer(list(nmt_data['machine_readable_date']),10,machine_readable_dates_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_cat_vector = np.array(to_categorical(X,len(human_readable_dates_vocab)))\n",
    "y_cat_vector = np.array(to_categorical(Y,len(machine_readable_dates_vocab)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " X :  (9548, 30)\n",
      " Y :  (9548, 10)\n",
      " x_cat_vector :  (9548, 30, 36)\n",
      " y_cat_vector :  (9548, 10, 11)\n"
     ]
    }
   ],
   "source": [
    "print(\" X : \",X.shape)\n",
    "print(\" Y : \",Y.shape)\n",
    "print(\" x_cat_vector : \",x_cat_vector.shape)\n",
    "print(\" y_cat_vector : \",y_cat_vector.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defined shared layers as global variables\n",
    "repeator = RepeatVector(Tx)\n",
    "concatenator = Concatenate(axis=-1)\n",
    "densor1 = Dense(10, activation = \"tanh\")\n",
    "densor2 = Dense(1, activation = \"relu\")\n",
    "activator = Activation('softmax', name='attention_weights') # We are using a custom softmax(axis = 1) loaded in this notebook\n",
    "dotor = Dot(axes = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# single step attention\n",
    "def one_step_attention(a, s_prev):\n",
    "    \n",
    "    s_prev = repeator(s_prev)\n",
    "    concat = concatenator([s_prev,a])\n",
    "    e = densor1(concat)\n",
    "    energies = densor2(e)\n",
    "    alphas = activator(energies)\n",
    "    context = dotor([alphas,a])\n",
    "    \n",
    "    return context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_a = 32 # number of units for the pre-attention, bi-directional LSTM's hidden state 'a'\n",
    "n_s = 64 # number of units for the post-attention LSTM's hidden state \"s\"\n",
    "\n",
    "# this is the post attention LSTM cell. \n",
    "post_activation_LSTM_cell = LSTM(n_s, return_state = True)\n",
    "output_layer = Dense(len(machine_readable_dates_vocab), activation='softmax')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using for loop on each token to generate attention on all tokens\n",
    "\n",
    "def modelf(Tx, Ty, n_a, n_s, human_vocab_size, machine_vocab_size):\n",
    "    \n",
    "    X = Input(shape=(Tx, human_vocab_size))\n",
    "    s0 = Input(shape=(n_s,), name='s0')\n",
    "    c0 = Input(shape=(n_s,), name='c0')\n",
    "    s = s0\n",
    "    c = c0\n",
    "    \n",
    "    outputs = []\n",
    "    \n",
    "    a = Bidirectional(LSTM(n_a,return_sequences=True))(X)\n",
    "    \n",
    "    for t in range(Ty):\n",
    "        \n",
    "        print(\"t : .....\",t)\n",
    "        context = one_step_attention(a,s)\n",
    "        s, _, c = post_activation_LSTM_cell(inputs=context, initial_state=[s,c])\n",
    "        out = output_layer(inputs=s)\n",
    "        outputs.append(out)\n",
    "    \n",
    "    model = Model(inputs=[X,s0,c0],outputs=outputs)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t : ..... 0\n",
      "t : ..... 1\n",
      "t : ..... 2\n",
      "t : ..... 3\n",
      "t : ..... 4\n",
      "t : ..... 5\n",
      "t : ..... 6\n",
      "t : ..... 7\n",
      "t : ..... 8\n",
      "t : ..... 9\n"
     ]
    }
   ],
   "source": [
    "model = modelf(Tx, Ty, n_a, n_s, len(human_readable_dates_vocab), len(machine_readable_dates_vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "s0 (InputLayer)                 [(None, 64)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_6 (InputLayer)            [(None, 30, 36)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "repeat_vector_5 (RepeatVector)  (None, 30, 64)       0           s0[0][0]                         \n",
      "                                                                 lstm_10[0][0]                    \n",
      "                                                                 lstm_10[1][0]                    \n",
      "                                                                 lstm_10[2][0]                    \n",
      "                                                                 lstm_10[3][0]                    \n",
      "                                                                 lstm_10[4][0]                    \n",
      "                                                                 lstm_10[5][0]                    \n",
      "                                                                 lstm_10[6][0]                    \n",
      "                                                                 lstm_10[7][0]                    \n",
      "                                                                 lstm_10[8][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_5 (Bidirectional) (None, 30, 64)       17664       input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 30, 128)      0           repeat_vector_5[0][0]            \n",
      "                                                                 bidirectional_5[0][0]            \n",
      "                                                                 repeat_vector_5[1][0]            \n",
      "                                                                 bidirectional_5[0][0]            \n",
      "                                                                 repeat_vector_5[2][0]            \n",
      "                                                                 bidirectional_5[0][0]            \n",
      "                                                                 repeat_vector_5[3][0]            \n",
      "                                                                 bidirectional_5[0][0]            \n",
      "                                                                 repeat_vector_5[4][0]            \n",
      "                                                                 bidirectional_5[0][0]            \n",
      "                                                                 repeat_vector_5[5][0]            \n",
      "                                                                 bidirectional_5[0][0]            \n",
      "                                                                 repeat_vector_5[6][0]            \n",
      "                                                                 bidirectional_5[0][0]            \n",
      "                                                                 repeat_vector_5[7][0]            \n",
      "                                                                 bidirectional_5[0][0]            \n",
      "                                                                 repeat_vector_5[8][0]            \n",
      "                                                                 bidirectional_5[0][0]            \n",
      "                                                                 repeat_vector_5[9][0]            \n",
      "                                                                 bidirectional_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_14 (Dense)                (None, 30, 10)       1290        concatenate_5[0][0]              \n",
      "                                                                 concatenate_5[1][0]              \n",
      "                                                                 concatenate_5[2][0]              \n",
      "                                                                 concatenate_5[3][0]              \n",
      "                                                                 concatenate_5[4][0]              \n",
      "                                                                 concatenate_5[5][0]              \n",
      "                                                                 concatenate_5[6][0]              \n",
      "                                                                 concatenate_5[7][0]              \n",
      "                                                                 concatenate_5[8][0]              \n",
      "                                                                 concatenate_5[9][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_15 (Dense)                (None, 30, 1)        11          dense_14[0][0]                   \n",
      "                                                                 dense_14[1][0]                   \n",
      "                                                                 dense_14[2][0]                   \n",
      "                                                                 dense_14[3][0]                   \n",
      "                                                                 dense_14[4][0]                   \n",
      "                                                                 dense_14[5][0]                   \n",
      "                                                                 dense_14[6][0]                   \n",
      "                                                                 dense_14[7][0]                   \n",
      "                                                                 dense_14[8][0]                   \n",
      "                                                                 dense_14[9][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "attention_weights (Activation)  (None, 30, 1)        0           dense_15[0][0]                   \n",
      "                                                                 dense_15[1][0]                   \n",
      "                                                                 dense_15[2][0]                   \n",
      "                                                                 dense_15[3][0]                   \n",
      "                                                                 dense_15[4][0]                   \n",
      "                                                                 dense_15[5][0]                   \n",
      "                                                                 dense_15[6][0]                   \n",
      "                                                                 dense_15[7][0]                   \n",
      "                                                                 dense_15[8][0]                   \n",
      "                                                                 dense_15[9][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dot_4 (Dot)                     (None, 1, 64)        0           attention_weights[0][0]          \n",
      "                                                                 bidirectional_5[0][0]            \n",
      "                                                                 attention_weights[1][0]          \n",
      "                                                                 bidirectional_5[0][0]            \n",
      "                                                                 attention_weights[2][0]          \n",
      "                                                                 bidirectional_5[0][0]            \n",
      "                                                                 attention_weights[3][0]          \n",
      "                                                                 bidirectional_5[0][0]            \n",
      "                                                                 attention_weights[4][0]          \n",
      "                                                                 bidirectional_5[0][0]            \n",
      "                                                                 attention_weights[5][0]          \n",
      "                                                                 bidirectional_5[0][0]            \n",
      "                                                                 attention_weights[6][0]          \n",
      "                                                                 bidirectional_5[0][0]            \n",
      "                                                                 attention_weights[7][0]          \n",
      "                                                                 bidirectional_5[0][0]            \n",
      "                                                                 attention_weights[8][0]          \n",
      "                                                                 bidirectional_5[0][0]            \n",
      "                                                                 attention_weights[9][0]          \n",
      "                                                                 bidirectional_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "c0 (InputLayer)                 [(None, 64)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_10 (LSTM)                  [(None, 64), (None,  33024       dot_4[0][0]                      \n",
      "                                                                 s0[0][0]                         \n",
      "                                                                 c0[0][0]                         \n",
      "                                                                 dot_4[1][0]                      \n",
      "                                                                 lstm_10[0][0]                    \n",
      "                                                                 lstm_10[0][2]                    \n",
      "                                                                 dot_4[2][0]                      \n",
      "                                                                 lstm_10[1][0]                    \n",
      "                                                                 lstm_10[1][2]                    \n",
      "                                                                 dot_4[3][0]                      \n",
      "                                                                 lstm_10[2][0]                    \n",
      "                                                                 lstm_10[2][2]                    \n",
      "                                                                 dot_4[4][0]                      \n",
      "                                                                 lstm_10[3][0]                    \n",
      "                                                                 lstm_10[3][2]                    \n",
      "                                                                 dot_4[5][0]                      \n",
      "                                                                 lstm_10[4][0]                    \n",
      "                                                                 lstm_10[4][2]                    \n",
      "                                                                 dot_4[6][0]                      \n",
      "                                                                 lstm_10[5][0]                    \n",
      "                                                                 lstm_10[5][2]                    \n",
      "                                                                 dot_4[7][0]                      \n",
      "                                                                 lstm_10[6][0]                    \n",
      "                                                                 lstm_10[6][2]                    \n",
      "                                                                 dot_4[8][0]                      \n",
      "                                                                 lstm_10[7][0]                    \n",
      "                                                                 lstm_10[7][2]                    \n",
      "                                                                 dot_4[9][0]                      \n",
      "                                                                 lstm_10[8][0]                    \n",
      "                                                                 lstm_10[8][2]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_16 (Dense)                (None, 11)           715         lstm_10[0][0]                    \n",
      "                                                                 lstm_10[1][0]                    \n",
      "                                                                 lstm_10[2][0]                    \n",
      "                                                                 lstm_10[3][0]                    \n",
      "                                                                 lstm_10[4][0]                    \n",
      "                                                                 lstm_10[5][0]                    \n",
      "                                                                 lstm_10[6][0]                    \n",
      "                                                                 lstm_10[7][0]                    \n",
      "                                                                 lstm_10[8][0]                    \n",
      "                                                                 lstm_10[9][0]                    \n",
      "==================================================================================================\n",
      "Total params: 52,704\n",
      "Trainable params: 52,704\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compiing the model\n",
    "opt = Adam(lr=0.005,beta_1=0.9,beta_2=0.999,decay=0.01) # Adam(...) \n",
    "model.compile(loss = 'categorical_crossentropy', optimizer = opt, metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = nmt_data.shape[0]\n",
    "s0 = np.zeros((m, n_s))\n",
    "c0 = np.zeros((m, n_s))\n",
    "outputs = list(y_cat_vector.swapaxes(0,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "96/96 [==============================] - 9s 90ms/step - loss: 5.1172 - dense_16_loss: 0.0654 - dense_16_1_loss: 0.0521 - dense_16_2_loss: 0.4998 - dense_16_3_loss: 0.9724 - dense_16_4_loss: 0.0295 - dense_16_5_loss: 0.2486 - dense_16_6_loss: 1.1535 - dense_16_7_loss: 0.0428 - dense_16_8_loss: 0.7029 - dense_16_9_loss: 1.3502 - dense_16_accuracy: 0.9853 - dense_16_1_accuracy: 0.9869 - dense_16_2_accuracy: 0.8371 - dense_16_3_accuracy: 0.6837 - dense_16_4_accuracy: 1.0000 - dense_16_5_accuracy: 0.9412 - dense_16_6_accuracy: 0.5829 - dense_16_7_accuracy: 0.9993 - dense_16_8_accuracy: 0.7463 - dense_16_9_accuracy: 0.4689\n",
      "Epoch 2/20\n",
      "96/96 [==============================] - 9s 94ms/step - loss: 3.9429 - dense_16_loss: 0.0512 - dense_16_1_loss: 0.0407 - dense_16_2_loss: 0.4341 - dense_16_3_loss: 0.6606 - dense_16_4_loss: 0.0166 - dense_16_5_loss: 0.1467 - dense_16_6_loss: 0.8566 - dense_16_7_loss: 0.0298 - dense_16_8_loss: 0.5722 - dense_16_9_loss: 1.1344 - dense_16_accuracy: 0.9876 - dense_16_1_accuracy: 0.9890 - dense_16_2_accuracy: 0.8489 - dense_16_3_accuracy: 0.8139 - dense_16_4_accuracy: 1.0000 - dense_16_5_accuracy: 0.9703 - dense_16_6_accuracy: 0.7220 - dense_16_7_accuracy: 0.9998 - dense_16_8_accuracy: 0.8001 - dense_16_9_accuracy: 0.5596\n",
      "Epoch 3/20\n",
      "96/96 [==============================] - 9s 94ms/step - loss: 3.1997 - dense_16_loss: 0.0437 - dense_16_1_loss: 0.0353 - dense_16_2_loss: 0.3817 - dense_16_3_loss: 0.4840 - dense_16_4_loss: 0.0109 - dense_16_5_loss: 0.1131 - dense_16_6_loss: 0.6810 - dense_16_7_loss: 0.0238 - dense_16_8_loss: 0.4941 - dense_16_9_loss: 0.9321 - dense_16_accuracy: 0.9882 - dense_16_1_accuracy: 0.9891 - dense_16_2_accuracy: 0.8606 - dense_16_3_accuracy: 0.8722 - dense_16_4_accuracy: 1.0000 - dense_16_5_accuracy: 0.9762 - dense_16_6_accuracy: 0.7977 - dense_16_7_accuracy: 0.9998 - dense_16_8_accuracy: 0.8328 - dense_16_9_accuracy: 0.6616: 2s - loss: 3.2747 - dense_16_loss: 0.0442 - dense_16_1_loss: 0.0366 - dense_16_2_loss: 0.3861 - dense_16_3_loss: 0.4996 - dense_16_4_loss: 0.0113 - dense_16_5_loss: 0.1170 - dense_16_6_loss: 0.7004 - dense_16_7_loss: 0.0241 - dense_16_8_loss: 0.5056 - dense_16_9_loss: 0.9499 - dense_16_accuracy: 0.9884 - dense_16_1_accuracy: 0.9892 - dense_16_2_accuracy: 0.8626 - dense_16_3_accuracy: 0.8672 - dense_16_4_accuracy: 1.0000 - dense_16_5_accuracy: 0.9753 - dense_16_6_accuracy: 0.7889 - dense_16_7_accuracy: 0.9999 - dense_16_8_accuracy: 0.8272 - dens\n",
      "Epoch 4/20\n",
      "96/96 [==============================] - 9s 94ms/step - loss: 2.6982 - dense_16_loss: 0.0387 - dense_16_1_loss: 0.0307 - dense_16_2_loss: 0.3457 - dense_16_3_loss: 0.3929 - dense_16_4_loss: 0.0083 - dense_16_5_loss: 0.0932 - dense_16_6_loss: 0.5576 - dense_16_7_loss: 0.0193 - dense_16_8_loss: 0.4367 - dense_16_9_loss: 0.7752 - dense_16_accuracy: 0.9894 - dense_16_1_accuracy: 0.9907 - dense_16_2_accuracy: 0.8644 - dense_16_3_accuracy: 0.8959 - dense_16_4_accuracy: 1.0000 - dense_16_5_accuracy: 0.9787 - dense_16_6_accuracy: 0.8450 - dense_16_7_accuracy: 0.9997 - dense_16_8_accuracy: 0.8560 - dense_16_9_accuracy: 0.7289: 6s - loss: 2.8478 - dense_16_loss: 0.0441 - dense_16_1_loss: 0.0366 - dense_16_2_loss: 0.3536 - dense_16_3_loss: 0.4192 - dense_16_4_loss: 0.0091 - dense_16_5_loss: 0.0992 - dense_16_6_loss: 0.5924 - dense_16_7_loss: 0.0206 - dense_16_8_loss: 0.4588 - dense_16_9_loss: 0.8140 - dense_16_accuracy: 0.9877 - dense_16_1_accuracy: 0.9882 - dense_16_2_accuracy: 0.8618 - dense_16_3_accuracy: 0.8845 - dense_16_4_accuracy: 1.0000 - dense_16_5_accuracy: 0.9777 - dense_16_6_accuracy: 0.8318 - dense_16_7_accuracy: 0.9995 - dense_16_8_accuracy: 0.8405 - dense_16_ - ETA: 5s - loss: 2.8043 - dense_16_loss: 0.0402 - dense_16_1_loss: 0.0329 - dense_16_2_loss: 0.3508 - dense_16_3_loss: 0.4067 - dense_16_4_loss: 0.0090 - dense_16_5_loss: 0.0956 - dense_16_6_loss: 0.5815 - dense_16_7_loss: 0.0203 - dense_16_8_loss: 0.4513 - dense_16_9_loss: 0.8159 - dense_16_accuracy: 0.9893 - dense_16_1_accuracy: 0.9905 - dense_16_2_accuracy: 0.8675 - dense_16_3_accuracy: 0.8930 - dense_16_4_accuracy: 1.0000 - dense_16_5_accuracy: 0.9800 - dense_16_6_accuracy: 0.8372 - dense_16_7_accuracy: 0.9995 - dense_16_8_accuracy: 0. - ETA: 2s - loss: 2.7488 - dense_16_loss: 0.0390 - dense_16_1_loss: 0.0311 - dense_16_2_loss: 0.3463 - dense_16_3_loss: 0.4028 - dense_16_4_loss: 0.0086 - dense_16_5_loss: 0.0952 - dense_16_6_loss: 0.5717 - dense_16_7_loss: 0.0197 - dense_16_8_loss: 0.4446 - dense_16_9_loss: 0.7897 - dense_16_accuracy: 0.9899 - dense_16_1_accuracy: 0.9908 - dense_16_2_accuracy: 0.8653 - dense_16_3_accuracy: 0.8927 - dense_16_4_accuracy: 1.0000 - dense_16_5_accuracy: 0.9788 - dense_16_6_accuracy: 0.8396 - dense_16_7_accuracy: 0.9996 - dense_16_8_accuracy: 0.8528 - dens\n",
      "Epoch 5/20\n",
      "96/96 [==============================] - 8s 87ms/step - loss: 2.3503 - dense_16_loss: 0.0362 - dense_16_1_loss: 0.0292 - dense_16_2_loss: 0.3270 - dense_16_3_loss: 0.3314 - dense_16_4_loss: 0.0067 - dense_16_5_loss: 0.0813 - dense_16_6_loss: 0.4728 - dense_16_7_loss: 0.0177 - dense_16_8_loss: 0.3882 - dense_16_9_loss: 0.6598 - dense_16_accuracy: 0.9901 - dense_16_1_accuracy: 0.9918 - dense_16_2_accuracy: 0.8618 - dense_16_3_accuracy: 0.9117 - dense_16_4_accuracy: 1.0000 - dense_16_5_accuracy: 0.9806 - dense_16_6_accuracy: 0.8758 - dense_16_7_accuracy: 0.9997 - dense_16_8_accuracy: 0.8741 - dense_16_9_accuracy: 0.7831\n",
      "Epoch 6/20\n",
      "96/96 [==============================] - 9s 93ms/step - loss: 2.0868 - dense_16_loss: 0.0333 - dense_16_1_loss: 0.0274 - dense_16_2_loss: 0.3091 - dense_16_3_loss: 0.2909 - dense_16_4_loss: 0.0056 - dense_16_5_loss: 0.0755 - dense_16_6_loss: 0.4125 - dense_16_7_loss: 0.0154 - dense_16_8_loss: 0.3482 - dense_16_9_loss: 0.5688 - dense_16_accuracy: 0.9909 - dense_16_1_accuracy: 0.9908 - dense_16_2_accuracy: 0.8652 - dense_16_3_accuracy: 0.9225 - dense_16_4_accuracy: 1.0000 - dense_16_5_accuracy: 0.9792 - dense_16_6_accuracy: 0.8977 - dense_16_7_accuracy: 1.0000 - dense_16_8_accuracy: 0.8895 - dense_16_9_accuracy: 0.8182\n",
      "Epoch 7/20\n",
      "96/96 [==============================] - 8s 87ms/step - loss: 1.8868 - dense_16_loss: 0.0311 - dense_16_1_loss: 0.0259 - dense_16_2_loss: 0.2948 - dense_16_3_loss: 0.2598 - dense_16_4_loss: 0.0047 - dense_16_5_loss: 0.0671 - dense_16_6_loss: 0.3689 - dense_16_7_loss: 0.0135 - dense_16_8_loss: 0.3176 - dense_16_9_loss: 0.5034 - dense_16_accuracy: 0.9909 - dense_16_1_accuracy: 0.9918 - dense_16_2_accuracy: 0.8678 - dense_16_3_accuracy: 0.9315 - dense_16_4_accuracy: 1.0000 - dense_16_5_accuracy: 0.9830 - dense_16_6_accuracy: 0.9102 - dense_16_7_accuracy: 0.9999 - dense_16_8_accuracy: 0.9006 - dense_16_9_accuracy: 0.8465\n",
      "Epoch 8/20\n",
      "96/96 [==============================] - 9s 95ms/step - loss: 1.7279 - dense_16_loss: 0.0300 - dense_16_1_loss: 0.0248 - dense_16_2_loss: 0.2840 - dense_16_3_loss: 0.2383 - dense_16_4_loss: 0.0043 - dense_16_5_loss: 0.0622 - dense_16_6_loss: 0.3291 - dense_16_7_loss: 0.0124 - dense_16_8_loss: 0.2885 - dense_16_9_loss: 0.4543 - dense_16_accuracy: 0.9905 - dense_16_1_accuracy: 0.9916 - dense_16_2_accuracy: 0.8702 - dense_16_3_accuracy: 0.9377 - dense_16_4_accuracy: 1.0000 - dense_16_5_accuracy: 0.9829 - dense_16_6_accuracy: 0.9243 - dense_16_7_accuracy: 0.9999 - dense_16_8_accuracy: 0.9149 - dense_16_9_accuracy: 0.8624\n",
      "Epoch 9/20\n",
      "96/96 [==============================] - 9s 89ms/step - loss: 1.6102 - dense_16_loss: 0.0286 - dense_16_1_loss: 0.0238 - dense_16_2_loss: 0.2747 - dense_16_3_loss: 0.2199 - dense_16_4_loss: 0.0040 - dense_16_5_loss: 0.0584 - dense_16_6_loss: 0.3013 - dense_16_7_loss: 0.0112 - dense_16_8_loss: 0.2685 - dense_16_9_loss: 0.4198 - dense_16_accuracy: 0.9913 - dense_16_1_accuracy: 0.9925 - dense_16_2_accuracy: 0.8729 - dense_16_3_accuracy: 0.9465 - dense_16_4_accuracy: 1.0000 - dense_16_5_accuracy: 0.9835 - dense_16_6_accuracy: 0.9307 - dense_16_7_accuracy: 1.0000 - dense_16_8_accuracy: 0.9231 - dense_16_9_accuracy: 0.8701\n",
      "Epoch 10/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96/96 [==============================] - 8s 88ms/step - loss: 1.5116 - dense_16_loss: 0.0278 - dense_16_1_loss: 0.0237 - dense_16_2_loss: 0.2662 - dense_16_3_loss: 0.2079 - dense_16_4_loss: 0.0035 - dense_16_5_loss: 0.0562 - dense_16_6_loss: 0.2820 - dense_16_7_loss: 0.0104 - dense_16_8_loss: 0.2485 - dense_16_9_loss: 0.3854 - dense_16_accuracy: 0.9908 - dense_16_1_accuracy: 0.9920 - dense_16_2_accuracy: 0.8730 - dense_16_3_accuracy: 0.9490 - dense_16_4_accuracy: 1.0000 - dense_16_5_accuracy: 0.9837 - dense_16_6_accuracy: 0.9336 - dense_16_7_accuracy: 1.0000 - dense_16_8_accuracy: 0.9321 - dense_16_9_accuracy: 0.8831: 3s - loss: 1.5150 - dense_16_loss: 0.0252 - dense_16_1_loss: 0.0212 - dense_16_2_loss: 0.2651 - dense_16_3_loss: 0.2096 - dense_16_4_loss: 0.0036 - dense_16_5_loss: 0.0575 - dense_16_6_loss: 0.2836 - dense_16_7_loss: 0.0108 - dense_16_8_loss: 0.2469 - dense_16_9_loss: 0.3915 - dense_16_accuracy: 0.9923 - dense_16_1_accuracy: 0.9937 - dense_16_2_accuracy: 0.8737 - dense_16_3_accuracy: 0.9468 - dense_16_4_accuracy: 1.0000 - dense_16_5_accuracy: 0.9832 - dense_16_6_accuracy: 0.9321 - dense_16_7_accuracy: 1.0000 - dense_16_8_accura\n",
      "Epoch 11/20\n",
      "96/96 [==============================] - 9s 93ms/step - loss: 1.4180 - dense_16_loss: 0.0265 - dense_16_1_loss: 0.0224 - dense_16_2_loss: 0.2566 - dense_16_3_loss: 0.1945 - dense_16_4_loss: 0.0033 - dense_16_5_loss: 0.0523 - dense_16_6_loss: 0.2606 - dense_16_7_loss: 0.0098 - dense_16_8_loss: 0.2318 - dense_16_9_loss: 0.3602 - dense_16_accuracy: 0.9913 - dense_16_1_accuracy: 0.9924 - dense_16_2_accuracy: 0.8783 - dense_16_3_accuracy: 0.9556 - dense_16_4_accuracy: 1.0000 - dense_16_5_accuracy: 0.9852 - dense_16_6_accuracy: 0.9410 - dense_16_7_accuracy: 1.0000 - dense_16_8_accuracy: 0.9384 - dense_16_9_accuracy: 0.8889\n",
      "Epoch 12/20\n",
      "96/96 [==============================] - 9s 92ms/step - loss: 1.3438 - dense_16_loss: 0.0258 - dense_16_1_loss: 0.0220 - dense_16_2_loss: 0.2486 - dense_16_3_loss: 0.1815 - dense_16_4_loss: 0.0031 - dense_16_5_loss: 0.0493 - dense_16_6_loss: 0.2461 - dense_16_7_loss: 0.0093 - dense_16_8_loss: 0.2189 - dense_16_9_loss: 0.3391 - dense_16_accuracy: 0.9912 - dense_16_1_accuracy: 0.9918 - dense_16_2_accuracy: 0.8835 - dense_16_3_accuracy: 0.9614 - dense_16_4_accuracy: 1.0000 - dense_16_5_accuracy: 0.9855 - dense_16_6_accuracy: 0.9433 - dense_16_7_accuracy: 1.0000 - dense_16_8_accuracy: 0.9430 - dense_16_9_accuracy: 0.8930: 2s - loss: 1.3459 - dense_16_loss: 0.0271 - dense_16_1_loss: 0.0233 - dense_16_2_loss: 0.2468 - dense_16_3_loss: 0.1807 - dense_16_4_loss: 0.0031 - dense_16_5_loss: 0.0502 - dense_16_6_loss: 0.2471 - dense_16_7_loss: 0.0091 - dense_16_8_loss: 0.2213 - dense_16_9_loss: 0.3373 - dense_16_accuracy: 0.9907 - dense_16_1_accuracy: 0.9914 - dense_16_2_accuracy: 0.8845 - dense_16_3_accuracy: 0.9613 - dense_16_4_accuracy: 1.0000 - dense_16_5_accuracy: 0.9851 - dense_16_6_accuracy: 0.9425 - dense_16_7_accuracy: 1.0000 - dense_16_8_accuracy: 0.9431 - d\n",
      "Epoch 13/20\n",
      "96/96 [==============================] - 9s 95ms/step - loss: 1.2761 - dense_16_loss: 0.0248 - dense_16_1_loss: 0.0212 - dense_16_2_loss: 0.2409 - dense_16_3_loss: 0.1720 - dense_16_4_loss: 0.0029 - dense_16_5_loss: 0.0469 - dense_16_6_loss: 0.2324 - dense_16_7_loss: 0.0084 - dense_16_8_loss: 0.2055 - dense_16_9_loss: 0.3211 - dense_16_accuracy: 0.9917 - dense_16_1_accuracy: 0.9922 - dense_16_2_accuracy: 0.8858 - dense_16_3_accuracy: 0.9639 - dense_16_4_accuracy: 1.0000 - dense_16_5_accuracy: 0.9853 - dense_16_6_accuracy: 0.9461 - dense_16_7_accuracy: 1.0000 - dense_16_8_accuracy: 0.9483 - dense_16_9_accuracy: 0.9011\n",
      "Epoch 14/20\n",
      "96/96 [==============================] - 8s 87ms/step - loss: 1.2161 - dense_16_loss: 0.0238 - dense_16_1_loss: 0.0205 - dense_16_2_loss: 0.2337 - dense_16_3_loss: 0.1633 - dense_16_4_loss: 0.0027 - dense_16_5_loss: 0.0442 - dense_16_6_loss: 0.2189 - dense_16_7_loss: 0.0083 - dense_16_8_loss: 0.1956 - dense_16_9_loss: 0.3050 - dense_16_accuracy: 0.9921 - dense_16_1_accuracy: 0.9929 - dense_16_2_accuracy: 0.8902 - dense_16_3_accuracy: 0.9673 - dense_16_4_accuracy: 1.0000 - dense_16_5_accuracy: 0.9860 - dense_16_6_accuracy: 0.9496 - dense_16_7_accuracy: 0.9999 - dense_16_8_accuracy: 0.9519 - dense_16_9_accuracy: 0.9042: 8s - loss: 1.2940 - dense_16_loss: 0.0270 - dense_16_1_loss: 0.0200 - dense_16_2_loss: 0.2754 - dense_16_3_loss: 0.1862 - dense_16_4_loss: 0.0028 - dense_16_5_loss: 0.0456 - dense_16_6_loss: 0.2095 - dense_16_7_loss: 0.0092 - dense_16_8_loss: 0.2012 - dense_16_9_loss: 0.3172 - dense_16_accuracy: 0.9900 - dense_16_1_accuracy: 0.9943 - dense_16_2_accuracy: 0.8571 - dense_16_3_accuracy: 0.9614 - dense_16_4_accuracy: 1.0000 - dense_16_5_accuracy: 0.9843 - dense_16_6_accuracy: 0.9600 \n",
      "Epoch 15/20\n",
      "96/96 [==============================] - 9s 92ms/step - loss: 1.1599 - dense_16_loss: 0.0236 - dense_16_1_loss: 0.0204 - dense_16_2_loss: 0.2246 - dense_16_3_loss: 0.1538 - dense_16_4_loss: 0.0026 - dense_16_5_loss: 0.0431 - dense_16_6_loss: 0.2115 - dense_16_7_loss: 0.0077 - dense_16_8_loss: 0.1858 - dense_16_9_loss: 0.2869 - dense_16_accuracy: 0.9924 - dense_16_1_accuracy: 0.9926 - dense_16_2_accuracy: 0.8966 - dense_16_3_accuracy: 0.9733 - dense_16_4_accuracy: 1.0000 - dense_16_5_accuracy: 0.9865 - dense_16_6_accuracy: 0.9521 - dense_16_7_accuracy: 0.9999 - dense_16_8_accuracy: 0.9555 - dense_16_9_accuracy: 0.9130\n",
      "Epoch 16/20\n",
      "96/96 [==============================] - 9s 93ms/step - loss: 1.1088 - dense_16_loss: 0.0230 - dense_16_1_loss: 0.0201 - dense_16_2_loss: 0.2174 - dense_16_3_loss: 0.1454 - dense_16_4_loss: 0.0024 - dense_16_5_loss: 0.0412 - dense_16_6_loss: 0.2015 - dense_16_7_loss: 0.0074 - dense_16_8_loss: 0.1760 - dense_16_9_loss: 0.2745 - dense_16_accuracy: 0.9920 - dense_16_1_accuracy: 0.9924 - dense_16_2_accuracy: 0.9026 - dense_16_3_accuracy: 0.9755 - dense_16_4_accuracy: 1.0000 - dense_16_5_accuracy: 0.9867 - dense_16_6_accuracy: 0.9521 - dense_16_7_accuracy: 1.0000 - dense_16_8_accuracy: 0.9604 - dense_16_9_accuracy: 0.9134: 4s - loss: 1.0996 - dense_16_loss: 0.0220 - dense_16_1_loss: 0.0174 - dense_16_2_loss: 0.2150 - dense_16_3_loss: 0.1427 - dense_16_4_loss: 0.0023 - dense_16_5_loss: 0.0390 - dense_16_6_loss: 0.1952 - dense_16_7_loss: 0.0078 - dense_16_8_loss: 0.1819 - dense_16_9_loss: 0.2765 - dense_16_accuracy: 0.9920 - dense_16_1_accuracy: 0.9934 - dense_16_2_accuracy: 0.9041 - dense_16_3_accuracy: 0.9739 - dense_16_4_accuracy: 1.0000 - dense_16_5_accuracy: 0.9884 - dense_16_6_accuracy: 0.9552 - dense_16_7_accuracy: 1.0000 - dens\n",
      "Epoch 17/20\n",
      "96/96 [==============================] - 9s 92ms/step - loss: 1.0641 - dense_16_loss: 0.0227 - dense_16_1_loss: 0.0198 - dense_16_2_loss: 0.2093 - dense_16_3_loss: 0.1369 - dense_16_4_loss: 0.0024 - dense_16_5_loss: 0.0398 - dense_16_6_loss: 0.1942 - dense_16_7_loss: 0.0072 - dense_16_8_loss: 0.1686 - dense_16_9_loss: 0.2634 - dense_16_accuracy: 0.9926 - dense_16_1_accuracy: 0.9931 - dense_16_2_accuracy: 0.9078 - dense_16_3_accuracy: 0.9787 - dense_16_4_accuracy: 1.0000 - dense_16_5_accuracy: 0.9871 - dense_16_6_accuracy: 0.9549 - dense_16_7_accuracy: 0.9999 - dense_16_8_accuracy: 0.9619 - dense_16_9_accuracy: 0.9188\n",
      "Epoch 18/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96/96 [==============================] - 8s 87ms/step - loss: 1.0214 - dense_16_loss: 0.0222 - dense_16_1_loss: 0.0190 - dense_16_2_loss: 0.2014 - dense_16_3_loss: 0.1293 - dense_16_4_loss: 0.0023 - dense_16_5_loss: 0.0380 - dense_16_6_loss: 0.1881 - dense_16_7_loss: 0.0067 - dense_16_8_loss: 0.1616 - dense_16_9_loss: 0.2529 - dense_16_accuracy: 0.9922 - dense_16_1_accuracy: 0.9925 - dense_16_2_accuracy: 0.9156 - dense_16_3_accuracy: 0.9815 - dense_16_4_accuracy: 1.0000 - dense_16_5_accuracy: 0.9868 - dense_16_6_accuracy: 0.9552 - dense_16_7_accuracy: 1.0000 - dense_16_8_accuracy: 0.9640 - dense_16_9_accuracy: 0.9211: 2s - loss: 1.0162 - dense_16_loss: 0.0216 - dense_16_1_loss: 0.0185 - dense_16_2_loss: 0.2037 - dense_16_3_loss: 0.1340 - dense_16_4_loss: 0.0023 - dense_16_5_loss: 0.0382 - dense_16_6_loss: 0.1846 - dense_16_7_loss: 0.0068 - dense_16_8_loss: 0.1579 - dense_16_9_loss: 0.2486 - dense_16_accuracy: 0.9925 - dense_16_1_accuracy: 0.9922 - dense_16_2_accuracy: 0.9138 - dense_16_3_accuracy: 0.9820 - dense_16_4_accuracy: 1.0000 - dense_16_5_accuracy: 0.9872 - dense_16_6_accuracy: 0.9563 - dense_16_7_accuracy: 1.0000 - dense_16_8_accuracy: 0.9652  - ETA: 0s - loss: 1.0211 - dense_16_loss: 0.0223 - dense_16_1_loss: 0.0189 - dense_16_2_loss: 0.2023 - dense_16_3_loss: 0.1295 - dense_16_4_loss: 0.0023 - dense_16_5_loss: 0.0379 - dense_16_6_loss: 0.1859 - dense_16_7_loss: 0.0068 - dense_16_8_loss: 0.1620 - dense_16_9_loss: 0.2533 - dense_16_accuracy: 0.9921 - dense_16_1_accuracy: 0.9923 - dense_16_2_accuracy: 0.9149 - dense_16_3_accuracy: 0.9817 - dense_16_4_accuracy: 1.0000 - dense_16_5_accuracy: 0.9870 - dense_16_6_accuracy: 0.9558 - dense_16_7_accuracy: 1.0000 - dense_16_8_accuracy: 0.9632 - dense_16_9_accuracy:\n",
      "Epoch 19/20\n",
      "96/96 [==============================] - 9s 95ms/step - loss: 0.9829 - dense_16_loss: 0.0219 - dense_16_1_loss: 0.0191 - dense_16_2_loss: 0.1943 - dense_16_3_loss: 0.1228 - dense_16_4_loss: 0.0022 - dense_16_5_loss: 0.0373 - dense_16_6_loss: 0.1826 - dense_16_7_loss: 0.0064 - dense_16_8_loss: 0.1535 - dense_16_9_loss: 0.2428 - dense_16_accuracy: 0.9926 - dense_16_1_accuracy: 0.9925 - dense_16_2_accuracy: 0.9197 - dense_16_3_accuracy: 0.9828 - dense_16_4_accuracy: 1.0000 - dense_16_5_accuracy: 0.9882 - dense_16_6_accuracy: 0.9561 - dense_16_7_accuracy: 1.0000 - dense_16_8_accuracy: 0.9660 - dense_16_9_accuracy: 0.9265\n",
      "Epoch 20/20\n",
      "96/96 [==============================] - 9s 95ms/step - loss: 0.9484 - dense_16_loss: 0.0215 - dense_16_1_loss: 0.0188 - dense_16_2_loss: 0.1863 - dense_16_3_loss: 0.1171 - dense_16_4_loss: 0.0021 - dense_16_5_loss: 0.0364 - dense_16_6_loss: 0.1772 - dense_16_7_loss: 0.0062 - dense_16_8_loss: 0.1491 - dense_16_9_loss: 0.2336 - dense_16_accuracy: 0.9925 - dense_16_1_accuracy: 0.9931 - dense_16_2_accuracy: 0.9265 - dense_16_3_accuracy: 0.9847 - dense_16_4_accuracy: 1.0000 - dense_16_5_accuracy: 0.9884 - dense_16_6_accuracy: 0.9579 - dense_16_7_accuracy: 1.0000 - dense_16_8_accuracy: 0.9672 - dense_16_9_accuracy: 0.9278\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x273ef395470>"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit([x_cat_vector, s0, c0], outputs, epochs=20, batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Unable to open file (unable to open file: name = 'models/model.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-130-5adfa8e1d454>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'models/model.h5'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\karthik reddy\\gen_venv\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mload_weights\u001b[1;34m(self, filepath, by_name, skip_mismatch, options)\u001b[0m\n\u001b[0;32m   2225\u001b[0m           'first, then load the weights.')\n\u001b[0;32m   2226\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_assert_weights_created\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2227\u001b[1;33m     \u001b[1;32mwith\u001b[0m \u001b[0mh5py\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'r'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2228\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[1;34m'layer_names'\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mattrs\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;34m'model_weights'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2229\u001b[0m         \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'model_weights'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\karthik reddy\\gen_venv\\lib\\site-packages\\h5py\\_hl\\files.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, **kwds)\u001b[0m\n\u001b[0;32m    406\u001b[0m                 fid = make_fid(name, mode, userblock_size,\n\u001b[0;32m    407\u001b[0m                                \u001b[0mfapl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfcpl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmake_fcpl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrack_order\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrack_order\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 408\u001b[1;33m                                swmr=swmr)\n\u001b[0m\u001b[0;32m    409\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    410\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlibver\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\karthik reddy\\gen_venv\\lib\\site-packages\\h5py\\_hl\\files.py\u001b[0m in \u001b[0;36mmake_fid\u001b[1;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[0;32m    171\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mswmr\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    172\u001b[0m             \u001b[0mflags\u001b[0m \u001b[1;33m|=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mACC_SWMR_READ\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 173\u001b[1;33m         \u001b[0mfid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    174\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'r+'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    175\u001b[0m         \u001b[0mfid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mACC_RDWR\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mh5py\\_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mh5py\\_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mh5py\\h5f.pyx\u001b[0m in \u001b[0;36mh5py.h5f.open\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: Unable to open file (unable to open file: name = 'models/model.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)"
     ]
    }
   ],
   "source": [
    "model.load_weights('models/model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "source: 3 May 1979\n",
      "output: 1979-05-03 \n",
      "\n",
      "source: 21th of August 2016\n",
      "output: 2016-08-21 \n",
      "\n",
      "source: Tue 10 Jul 2007\n",
      "output: 2007-07-10 \n",
      "\n",
      "source: Saturday May 9 2018\n",
      "output: 2018-05-09 \n",
      "\n",
      "source: March 3 2001\n",
      "output: 2001-03-03 \n",
      "\n",
      "source: March 3rd 2001\n",
      "output: 2001-03-03 \n",
      "\n",
      "source: 1 March 2001\n",
      "output: 2001-03-01 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# sample predicitons\n",
    "EXAMPLES = ['3 May 1979', '21th of August 2016', 'Tue 10 Jul 2007', 'Saturday May 9 2018', 'March 3 2001', 'March 3rd 2001', '1 March 2001']\n",
    "s00 = np.zeros((1, n_s))\n",
    "c00 = np.zeros((1, n_s))\n",
    "for example in EXAMPLES:\n",
    "    source = string_to_int(example, Tx, human_readable_dates_vocab)\n",
    "    #print(source)\n",
    "    source = np.array(list(map(lambda x: to_categorical(x, num_classes=len(human_readable_dates_vocab)), source))).swapaxes(0,1)\n",
    "    source = np.swapaxes(source, 0, 1)\n",
    "    source = np.expand_dims(source, axis=0)\n",
    "    prediction = model.predict([source, s00, c00])\n",
    "    prediction = np.argmax(prediction, axis = -1)\n",
    "    output = [inv_machine_readable_dates_vocab[int(i)] for i in prediction]\n",
    "    print(\"source:\", example)\n",
    "    print(\"output:\", ''.join(output),\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
